{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\".env\")\n",
    "APIKEY = config[\"RAPIDAPI\"][\"KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of Data Extraction Process\n",
    "\n",
    " ---\n",
    " \n",
    " Using the RapidApi, the data will be collected in the following order.\n",
    " \n",
    " * The symbols of market movers will be gotten using the endpoint \"market/v2/get-movers\" \n",
    " * The market movers will be added as query to the endpoint \"stock/v3/get-historical-data\" to collect historical data of the tickers\n",
    " * The symbols of the market movers will also be used as query to get their summary which includes the financial earnings using the endpoint stock/v2/get-summary\n",
    " * Currency pairs selected for the project are used as query in the endpoint \"market/get-spark\" to collect data according to interval and range. \n",
    " * The collected data will initially be saved in pandas dataframe.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract 10 stock losers, gainers and most-active stocks in GB region, get their symbols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://yh-finance.p.rapidapi.com/market/v2/get-movers\"\n",
    "\n",
    "querystring = {\"region\":\"GB\",\"lang\":\"en-GB\",\"count\":\"10\",\"start\":\"0\"}\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": APIKEY,\n",
    "\t\"X-RapidAPI-Host\": \"yh-finance.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=querystring).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the gainers from quotes\n",
    "gainer_quotes = response[\"finance\"][\"result\"][0][\"quotes\"]\n",
    "gainers = []\n",
    "\n",
    "for quote in gainer_quotes:\n",
    "    gainers.append(quote[\"symbol\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the losers\n",
    "losers_quotes = response[\"finance\"][\"result\"][1][\"quotes\"]\n",
    "losers = []\n",
    "\n",
    "for quote in losers_quotes:\n",
    "    losers.append(quote[\"symbol\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most actives\n",
    "mostactives_quotes = response[\"finance\"][\"result\"][2][\"quotes\"]\n",
    "mostactives = []\n",
    "\n",
    "for quote in mostactives_quotes:\n",
    "    mostactives.append(quote[\"symbol\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gainers</th>\n",
       "      <th>losers</th>\n",
       "      <th>mostactives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0BDR.IL</td>\n",
       "      <td>0JI3.L</td>\n",
       "      <td>7DIG.L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0MC5.IL</td>\n",
       "      <td>0E2B.IL</td>\n",
       "      <td>ICON.L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0RCP.IL</td>\n",
       "      <td>0AAT.IL</td>\n",
       "      <td>KOD.L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TUIB.L</td>\n",
       "      <td>MH65.L</td>\n",
       "      <td>SYME.L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0RCS.IL</td>\n",
       "      <td>0AAS.IL</td>\n",
       "      <td>0VRF.L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0RCR.IL</td>\n",
       "      <td>0V6Y.L</td>\n",
       "      <td>0MRI.IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0XC6.IL</td>\n",
       "      <td>0OI0.L</td>\n",
       "      <td>PREM.L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0E4B.IL</td>\n",
       "      <td>0A5O.IL</td>\n",
       "      <td>0RQY.L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0I21.L</td>\n",
       "      <td>0MN3.IL</td>\n",
       "      <td>BOIL.L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0DP0.IL</td>\n",
       "      <td>0XWG.IL</td>\n",
       "      <td>GST.L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gainers   losers mostactives\n",
       "0  0BDR.IL   0JI3.L      7DIG.L\n",
       "1  0MC5.IL  0E2B.IL      ICON.L\n",
       "2  0RCP.IL  0AAT.IL       KOD.L\n",
       "3   TUIB.L   MH65.L      SYME.L\n",
       "4  0RCS.IL  0AAS.IL      0VRF.L\n",
       "5  0RCR.IL   0V6Y.L     0MRI.IL\n",
       "6  0XC6.IL   0OI0.L      PREM.L\n",
       "7  0E4B.IL  0A5O.IL      0RQY.L\n",
       "8   0I21.L  0MN3.IL      BOIL.L\n",
       "9  0DP0.IL  0XWG.IL       GST.L"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all into one DF\n",
    "movers_df = pd.DataFrame(list(zip(gainers, losers, mostactives)), columns=['gainers', 'losers', 'mostactives'])\n",
    "\n",
    "movers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save movers in csv\n",
    "movers_df.to_csv(\"data/movers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract historical data with the symbols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import movers csv\n",
    "movers_df = pd.read_csv(\"data/movers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_data(path, movers, key):\n",
    "    \"\"\"\n",
    "    \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    url = \"https://yh-finance.p.rapidapi.com/stock/v3/get-historical-data\"\n",
    "    for symbol in movers_df[movers]: \n",
    "        querystring = {\"symbol\": symbol,\"region\":\"GB\"}\n",
    "\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Key\": key,\n",
    "            \"X-RapidAPI-Host\": \"yh-finance.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "        \n",
    "        names = ['date', 'open', 'high', 'low', 'close', 'volume', 'adjclose', 'symbol', 'movers']\n",
    "        for stock in response[\"prices\"]:\n",
    "            if len(stock) == 7:\n",
    "                history_data = {'date': stock['date'], \n",
    "                                'open': stock['open'], \n",
    "                                'high': stock['high'], \n",
    "                                'low': stock['low'],\n",
    "                                'close': stock['close'], 'volume': stock['volume'], \n",
    "                                'adjclose': stock['adjclose'], 'symbol': symbol,\n",
    "                                'movers': movers}\n",
    "                \n",
    "                data.append(history_data)\n",
    "        with open(path, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=names)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect historical data of each stock\n",
    "history_data(\"data/gainers_history.csv\", \"gainers\", APIKEY)\n",
    "history_data(\"data/losers_history.csv\", \"losers\", APIKEY)\n",
    "history_data(\"data/actives_history.csv\", \"mostactives\", APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine history stocks data into one dataframe\n",
    "gainers_history = pd.read_csv(\"data/gainers_history.csv\")\n",
    "losers_history = pd.read_csv(\"data/losers_history.csv\")\n",
    "actives_history = pd.read_csv(\"data/actives_history.csv\")\n",
    "\n",
    "stocks_history = pd.concat([gainers_history,losers_history, actives_history], ignore_index=True)\n",
    "stocks_history.to_csv(\"data/stocks_history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Summary and Financial information of each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_summary_earnings(path, movers):\n",
    "    \"\"\"\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    cols = [\"symbol\", \"summary\", \"quoteType\", \"beta\", \"dividendRate\", \"marketCap\",\"dividendYield\",\"exDividendDate\",\"dayHigh\",\n",
    "           \"dayLow\",\"ask\", \"previousClose\", \"marketOpen\", \"bid\", \"askSize\", \"bidSize\", \"volume\", \"fiftyTwoWeekHigh\", \"fiftyTwoWeekLow\",\n",
    "           \"earnings\"]\n",
    "    for symbol in movers_df[movers]: \n",
    "        url = \"https://yh-finance.p.rapidapi.com/stock/v2/get-summary\"\n",
    "\n",
    "        querystring = {\"symbol\":symbol,\"region\":\"US\"}\n",
    "\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Key\": APIKEY,\n",
    "            \"X-RapidAPI-Host\": \"yh-finance.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "        summaryDetail = response.get(\"summaryDetail\", {})\n",
    "        try:\n",
    "            profile_earnings = {\n",
    "               \"symbol\": symbol,\n",
    "               \"summary\": response.get(\"summaryProfile\", {}),\n",
    "               \"quoteType\": response.get(\"quoteType\", {}).get(\"quoteType\", \"\"),\n",
    "               \"beta\": summaryDetail.get(\"beta\", {}).get(\"raw\", 0),\n",
    "               \"dividendRate\": summaryDetail.get(\"dividendRate\",{}).get(\"raw\", 0),\n",
    "               \"marketCap\": summaryDetail.get(\"marketCap\", {}).get(\"raw\", 0),\n",
    "               \"dividendYield\": summaryDetail.get(\"dividendYield\", {}).get(\"raw\", 0),\n",
    "               \"exDividendDate\": summaryDetail.get(\"exDividendDate\", {}).get(\"raw\", 0),\n",
    "               \"dayHigh\": summaryDetail.get(\"dayHigh\", {}).get(\"raw\", 0),\n",
    "               \"dayLow\": summaryDetail.get(\"dayLow\", {}).get(\"raw\", 0),\n",
    "               \"ask\": summaryDetail.get(\"ask\", {}).get(\"raw\", 0),\n",
    "               \"previousClose\": summaryDetail.get(\"previousClose\", {}).get(\"raw\", 0),\n",
    "               \"marketOpen\": summaryDetail.get(\"open\", {}).get(\"raw\", 0),\n",
    "               \"bid\": summaryDetail.get(\"bid\", {}).get(\"raw\", 0),\n",
    "               \"askSize\": summaryDetail.get(\"askSize\", {}).get(\"raw\", 0),\n",
    "               \"bidSize\": summaryDetail.get(\"bidSize\", {}).get(\"raw\", 0),\n",
    "               \"volume\": summaryDetail.get(\"volume\", {}).get(\"raw\", 0),\n",
    "               \"fiftyTwoWeekHigh\": summaryDetail.get(\"fiftyTwoWeekHigh\", {}).get(\"raw\", 0),\n",
    "               \"fiftyTwoWeekLow\": summaryDetail.get(\"fiftyTwoWeekLow\", {}).get(\"raw\", 0),\n",
    "               \"earnings\": response.get(\"earnings\", {}).get(\"financialsChart\", {}).get(\"yearly\", {})\n",
    "            }\n",
    "            data.append(profile_earnings) \n",
    "        except Exception as E:\n",
    "            print(f'There is an error {E} in the data')\n",
    "            \n",
    "        with open(path, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=cols)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_summary_earnings(\"data/gainers_profile_earnings.csv\", \"gainers\")\n",
    "quote_summary_earnings(\"data/losers_profile_earnings.csv\", \"losers\")\n",
    "quote_summary_earnings(\"data/actives_profile_earnings.csv\", \"mostactives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine stocks profile earnings data into stock_profile_earnings\n",
    "gainers_profile_earnings = pd.read_csv(\"data/gainers_profile_earnings.csv\", encoding='latin1')\n",
    "losers_profile_earnings = pd.read_csv(\"data/losers_profile_earnings.csv\",encoding='latin1' )\n",
    "actives_profile_earnings = pd.read_csv(\"data/actives_profile_earnings.csv\",encoding='latin1')\n",
    "\n",
    "stock_profile_earnings = pd.concat([gainers_profile_earnings, losers_profile_earnings, actives_profile_earnings], ignore_index=True)\n",
    "stock_profile_earnings.to_csv(\"data/stock_profile_earnings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Historical data of 10 currency pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "The currency data will be collected as follows\n",
    " * Extract records using endpoint \"market/get-spark\"\n",
    " * Get 1min - 5day, 5min - 1mo, 1day - 6mo and 1wk - 1yr interval range of each pair\n",
    " * Extract according to interval. Combine later\n",
    " * The currencies symbol include: \n",
    "   GBPAUD=X,GBPUSD=X,GBPEUR=X,GBPJPY=X,GBPCAD=X,EURJPY=X,EURGBP,EURUSD=X,AUDUSD=X,NZDUSD=X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currencies(path, interval, rang, currencies):\n",
    "    \"\"\"\n",
    "        \n",
    "   \"\"\" \n",
    "    url = \"https://yh-finance.p.rapidapi.com/market/get-spark\"\n",
    "\n",
    "    querystring = {\"symbols\": (\",\").join(currencies), \"interval\":interval, \"range\": rang}\n",
    "\n",
    "    headers = {\n",
    "    \t\"X-RapidAPI-Key\": APIKEY,\n",
    "    \t\"X-RapidAPI-Host\": \"yh-finance.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring).json()\n",
    "    data = []\n",
    "    cols = [\"symbol\", \"timestamp\", \"close\", \"endTime\", \"startTime\", \"chartPrevClose\", \"interval\", \"range\"]\n",
    "    for pair in response:\n",
    "        for timeDur in range(len(response[pair][\"timestamp\"])):\n",
    "            currency_data = {\n",
    "                \"symbol\": pair,\n",
    "                \"timestamp\": response[pair][\"timestamp\"][timeDur],\n",
    "                \"close\": response[pair][\"close\"][timeDur],\n",
    "                \"endTime\": response[pair][\"end\"],\n",
    "                \"startTime\": response[pair][\"start\"],\n",
    "                \"chartPrevClose\": response[pair][\"chartPreviousClose\"],\n",
    "                \"interval\": interval,\n",
    "                \"range\": rang\n",
    "            }\n",
    "            \n",
    "            data.append(currency_data)\n",
    "    with open(path, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=cols)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "currencies = [\"GBPAUD=X\",\"GBPUSD=X\",\"GBPEUR=X\",\"GBPJPY=X\",\"GBPCAD=X\",\"EURJPY=X\",\"EURGBP=X\",\"EURUSD=X\",\"AUDUSD=X\",\"NZDUSD=X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_currencies(\"data/interRang1m5d.csv\", \"1m\", \"5d\", currencies)\n",
    "get_currencies(\"data/interRang5m1mo.csv\", \"5m\", \"1mo\", currencies)\n",
    "get_currencies(\"data/interRang1d6mo.csv\", \"1d\", \"6mo\", currencies)\n",
    "get_currencies(\"data/interRang1wk1y.csv\", \"1wk\", \"1y\", currencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical_currencies\n",
    "interRang1m5d = pd.read_csv(\"data/interRang1m5d.csv\")\n",
    "interRang5m1mo = pd.read_csv(\"data/interRang5m1mo.csv\")\n",
    "interRang1d6mo = pd.read_csv(\"data/interRang1d6mo.csv\")\n",
    "interRang1wk1y = pd.read_csv(\"data/interRang1wk1y.csv\")\n",
    "\n",
    "history_currencies = pd.concat([interRang1m5d,interRang5m1mo,interRang1d6mo,interRang1wk1y], ignore_index=True)\n",
    "history_currencies.to_csv(\"data/history_currencies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "---\n",
    "\n",
    "The profile and earning data will be transformed to extract data from any imbedded dictonary, the following will be done and achieved.\n",
    "\n",
    "* Check dictionary columns and collect relevant data. If dictionary doesn't contain a value, use a substitute.\n",
    "* Decide which records are needed, create new dataframe if columns are many\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of Data Cleaning Process\n",
    "\n",
    "---\n",
    "\n",
    "  The collected data will here be cleaned and processed.\n",
    "  The historical stocks, currencies and stocks profile and earnings data will be processed first by the following steps\n",
    "  \n",
    "  * Combine the related DataFrames\n",
    "  * Check for missing or Null values in the columns\n",
    "  * Remove or substitute for missing and null values\n",
    "  * Check statistics of data\n",
    "  * Save cleaned data in DF\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modelling, Loading and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
